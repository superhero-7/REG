{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset into memory...\n",
      "creating index...\n",
      "index created.\n",
      "DONE (t=3.00s)\n",
      "loading dataset into memory...\n",
      "creating index...\n",
      "index created.\n",
      "DONE (t=0.23s)\n"
     ]
    }
   ],
   "source": [
    "#先test产生outputs\n",
    "from baseline import LanguagePlusImage\n",
    "from Config import Config\n",
    "from data import ReferExpressionDataset\n",
    "from refer import REFER\n",
    "\n",
    "use_train_dataset = False\n",
    "\n",
    "cfg = Config()\n",
    "refer = REFER(cfg, train=True)\n",
    "refer_val = REFER(cfg, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "Using cuda\n",
      "Using cuda\n",
      "Freeze image network weights\n"
     ]
    }
   ],
   "source": [
    "dataset = ReferExpressionDataset(cfg, refer, split=False) # 用来训练的\n",
    "val_dataset = ReferExpressionDataset(cfg, refer_val) # 用来验证的\n",
    "#test_dataset = ReferExpressionDataset(cfg, refer, split=True, test=True)\n",
    "test_dataset = ReferExpressionDataset(cfg, refer_val, test=True)\n",
    "test_train_dataset = ReferExpressionDataset(cfg, refer, test=True,split=False) # 用训练数据测试看看，安慰自己\n",
    "model = LanguagePlusImage(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'checkpoints/default.mdl.checkpoint119'\n",
      "=> loaded checkpoint 'checkpoints/default.mdl.checkpoint119' (epoch 119)\n"
     ]
    }
   ],
   "source": [
    "checkpt_file = 'checkpoints/default.mdl.checkpoint119'\n",
    "model.load_model(checkpt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test None: 100%|███████████████████████████████████████████████████████████████████| 5000/5000 [18:25<00:00,  4.52it/s]\n"
     ]
    }
   ],
   "source": [
    "if use_train_dataset:\n",
    "    outputs = model.run_test(test_train_dataset)\n",
    "else:\n",
    "    outputs = model.run_test(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array(outputs)\n",
    "np.save('a.npy',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "outputs = np.load('a.npy',allow_pickle=True)\n",
    "outputs = outputs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用来产生comprehesion_output文件的\n",
    "import json\n",
    "\n",
    "comprehension_val_inputs = []\n",
    "for output in outputs:\n",
    "    comprehension_val_input = dict()\n",
    "    predicted_bounding_boxes = []\n",
    "    ann_id = output['annID'][0].numpy()[0]\n",
    "    comprehension_val_input['annotation_id'] = int(ann_id)\n",
    "    \n",
    "    \n",
    "    if use_train_dataset:\n",
    "        imageID = refer.Anns[str(ann_id)]['image_id']\n",
    "        region_candidates = refer.Imgs[str(imageID)]['region_candidates']\n",
    "        bboxes = [region_candidate['bounding_box'] for region_candidate in region_candidates]\n",
    "        tmp = []\n",
    "        tmp.append(refer.Anns[str(ann_id )]['bbox'])\n",
    "        tmp[1:] = bboxes[:]\n",
    "        bboxes = tmp\n",
    "    else:\n",
    "        imageID = refer_val.Anns[str(ann_id)]['image_id']\n",
    "        region_candidates = refer_val.Imgs[str(imageID)]['region_candidates']\n",
    "        bboxes = [region_candidate['bounding_box'] for region_candidate in region_candidates]\n",
    "        tmp = []\n",
    "        tmp.append(refer_val.Anns[str(ann_id )]['bbox'])\n",
    "        tmp[1:] = bboxes[:]\n",
    "        bboxes = tmp\n",
    "        \n",
    "    for idx in output['sorted_bboxes_idx']:\n",
    "        predicted_bounding_boxes.append(bboxes[idx])\n",
    "    comprehension_val_input['predicted_bounding_boxes'] = predicted_bounding_boxes\n",
    "    comprehension_val_inputs.append(comprehension_val_input)\n",
    "\n",
    "if use_train_dataset:\n",
    "    comprehension_file_name = 'comprehension_train.json'\n",
    "else:\n",
    "    comprehension_file_name = 'comprehension.json'\n",
    "with open(comprehension_file_name, 'w') as f:\n",
    "    json.dump(comprehension_val_inputs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "\n",
    "# MAKE Sure that google_refexp_py_lib is in your python libary search path\n",
    "# before you run API in this toolbox. You can use something as follows:aa\n",
    "sys.path.append('./google_refexp_py_lib')  # 这句是干什么的\n",
    "from refexp_eval import RefexpEvalComprehension\n",
    "from common_utils import draw_bbox\n",
    "\n",
    "use_train_data = False\n",
    "\n",
    "# Set coco_data_path and Google Refexp dataset validation set path\n",
    "if use_train_data:\n",
    "    refexp_dataset_path = './google_refexp_dataset_release/google_refexp_train_201511_coco_aligned.json'\n",
    "else:\n",
    "    refexp_dataset_path = './google_refexp_dataset_release/google_refexp_val_201511_coco_aligned.json'\n",
    "coco_data_path = '../Google_Refexp_toolbox-master/external/coco/annotations/instances_train2014.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Google Refexp dataset file for the comprehension task.\n",
      "loading annotations into memory...\n",
      "Done (t=14.05s)\n",
      "creating index...\n",
      "index created!\n",
      "Dataset loaded.\n"
     ]
    }
   ],
   "source": [
    "# Load Google Refexp dataset and MS COCO dataset (takes some time)\n",
    "eval_compreh = RefexpEvalComprehension(refexp_dataset_path, coco_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading predicted result file for the comprehension task.\n",
      "The average prec@1 score is 0.499\n"
     ]
    }
   ],
   "source": [
    "# We evalute a sample comprehension task results generated by\n",
    "# a naive method which outputs the groundtruth bounding boxes\n",
    "# in the coco image with a random order.  这一块究竟是个什么意思呢？！\n",
    "if use_train_data:\n",
    "    pred_results_path = 'comprehension_train.json'\n",
    "else:\n",
    "    pred_results_path = 'comprehension.json'\n",
    "\n",
    "(prec, eval_results) = eval_compreh.evaluate(pred_results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
